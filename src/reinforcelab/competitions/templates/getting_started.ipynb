{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"logo.png\" alt=\"Competition Logo\" width=\"200\"/>\n",
        "\n",
        "# ___TITLE___\n",
        "\n",
        "Welcome to the competition! This notebook will help you get started. You'll learn how to:\n",
        "1. Initialize and interact with the environment\n",
        "2. Use the default agent from `submission_contents` (train, save, evaluate)\n",
        "3. Run local evaluation using `run_local.py`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup\n",
        "\n",
        "First, let's install the required dependencies:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q -r submission_contents/requirements.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Initialize the Environment\n",
        "\n",
        "Let's create and explore the environment:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "\n",
        "# Environment ID for this competition\n",
        "ENV_ID = \"___ENV_ID___\"\n",
        "\n",
        "# Create the environment\n",
        "env = gym.make(ENV_ID)\n",
        "\n",
        "print(f\"Environment: {ENV_ID}\")\n",
        "print(f\"Observation Space: {env.observation_space}\")\n",
        "print(f\"Action Space: {env.action_space}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Render the Initial State\n",
        "\n",
        "Let's reset the environment and try to render the initial state:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reset the environment to get the initial observation\n",
        "observation, info = env.reset()\n",
        "\n",
        "print(f\"Initial Observation: {observation}\")\n",
        "print(f\"Observation Shape: {observation.shape if hasattr(observation, 'shape') else type(observation)}\")\n",
        "\n",
        "# Try to render the environment (may not work in all environments)\n",
        "try:\n",
        "    env_render = gym.make(ENV_ID, render_mode=\"rgb_array\")\n",
        "    env_render.reset()\n",
        "    frame = env_render.render()\n",
        "    \n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(frame)\n",
        "    plt.title(\"Initial State\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    env_render.close()\n",
        "except Exception as e:\n",
        "    print(f\"Rendering not available: {e}\")\n",
        "    print(\"This is normal for some environments. You can still train and evaluate agents.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Agent from submission_contents\n",
        "\n",
        "Import the default agent from the `submission_contents` folder. This agent takes random actions and demonstrates save/load with a pickle checkpoint:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import and create the agent from submission_contents\n",
        "from submission_contents.agent import Agent\n",
        "\n",
        "agent = Agent(env)\n",
        "print(f\"Agent created: {type(agent).__name__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Take a Random Action and Render\n",
        "\n",
        "Let's use the agent to take a random action and see what happens:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reset the environment\n",
        "observation, info = env.reset()\n",
        "\n",
        "# Get a random action from the agent\n",
        "action = agent.act(observation)\n",
        "print(f\"Action taken: {action}\")\n",
        "\n",
        "# Take a step in the environment\n",
        "next_observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "print(f\"\\nStep Result:\")\n",
        "print(f\"  Reward: {reward}\")\n",
        "print(f\"  Terminated: {terminated}\")\n",
        "print(f\"  Truncated: {truncated}\")\n",
        "print(f\"  Next Observation: {next_observation}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Try to render the state after taking an action\n",
        "try:\n",
        "    env_render = gym.make(ENV_ID, render_mode=\"rgb_array\")\n",
        "    env_render.reset()\n",
        "    env_render.step(action)\n",
        "    frame = env_render.render()\n",
        "    \n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(frame)\n",
        "    plt.title(f\"State after action: {action}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    env_render.close()\n",
        "except Exception as e:\n",
        "    print(f\"Rendering not available: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Train and Save\n",
        "\n",
        "Run a short training loop and save the agent. This demonstrates the train/save flow before evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent.train()\n",
        "agent.save()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Run a Full Episode\n",
        "\n",
        "Let's run a complete episode and track the total reward:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_episode(env, agent, max_steps=1000):\n",
        "    \"\"\"Run a single episode and return the total reward.\"\"\"\n",
        "    observation, _ = env.reset()\n",
        "    total_reward = 0\n",
        "    steps = 0\n",
        "    \n",
        "    done = False\n",
        "    while not done and steps < max_steps:\n",
        "        action = agent.act(observation)\n",
        "        observation, reward, terminated, truncated, _ = env.step(action)\n",
        "        total_reward += reward\n",
        "        done = terminated or truncated\n",
        "        steps += 1\n",
        "    \n",
        "    return total_reward, steps\n",
        "\n",
        "# Run multiple episodes to get average performance\n",
        "num_episodes = 10\n",
        "rewards = []\n",
        "\n",
        "for ep in range(num_episodes):\n",
        "    reward, steps = run_episode(env, agent)\n",
        "    rewards.append(reward)\n",
        "    print(f\"Episode {ep + 1}: Reward = {reward:.2f}, Steps = {steps}\")\n",
        "\n",
        "print(f\"\\n--- Random Agent Baseline ---\")\n",
        "print(f\"Average Reward: {np.mean(rewards):.2f}\")\n",
        "print(f\"Std Deviation: {np.std(rewards):.2f}\")\n",
        "print(f\"Min/Max: {np.min(rewards):.2f} / {np.max(rewards):.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Using run_local.py for Evaluation\n",
        "\n",
        "The `run_local.py` script tests your agent from `submission_contents` locally before submitting. It runs the same evaluation that Codabench will use:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the local evaluation script (uses agent from submission_contents)\n",
        "import subprocess\n",
        "result = subprocess.run(['python', 'run_local.py'], capture_output=True, text=True)\n",
        "print(result.stdout)\n",
        "if result.stderr:\n",
        "    print(\"Errors:\", result.stderr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Next Steps\n",
        "\n",
        "Now that you understand the basics, here's how to create your own agent:\n",
        "\n",
        "1. **Edit the agent**: Modify `submission_contents/agent.py` to implement your RL algorithm:\n",
        "   - `__init__(self, env)`: Initialize your model/network\n",
        "   - `act(self, observation)`: Return an action given the current observation\n",
        "   - `train(self)`: Train your agent on the environment\n",
        "   - `load(self)`: Load saved model weights from your checkpoint\n",
        "   - `save(self)`: Save your trained model\n",
        "\n",
        "2. **Test locally**: Use `run_local.py` to test your implementation\n",
        "\n",
        "3. **Build a submission**: Use `utils/build_submission.py` to zip `submission_contents` (see below)\n",
        "\n",
        "4. **Submit**: Upload the zip to the competition page\n",
        "\n",
        "Good luck! ðŸš€\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Building a Submission\n",
        "\n",
        "The `utils/build_submission.py` script creates a zip file ready for submission. It zips the **contents** of a folder (not the folder itself), which is what Codabench expects.\n",
        "\n",
        "**From the command line** (run from the starting kit directory):\n",
        "\n",
        "```bash\n",
        "# Default: zips submission_contents/ â†’ submission.zip\n",
        "python utils/build_submission.py\n",
        "\n",
        "# Custom input and output\n",
        "python utils/build_submission.py -i submission_contents -o my_submission.zip\n",
        "```\n",
        "\n",
        "**Options:**\n",
        "- `-i`, `--input`: Folder to zip (default: `submission_contents`)\n",
        "- `-o`, `--output`: Output zip path (default: `submission.zip`)\n",
        "\n",
        "Place your `agent.py`, checkpoint files (e.g. `checkpoint.pkl`), and `requirements.txt` in `submission_contents`, then run `utils/build_submission.py` and upload the zip to the competition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean up\n",
        "env.close()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
